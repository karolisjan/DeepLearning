{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Sentiment Classification\n",
    "\n",
    "Classification of the sentiment in [IMDB movie reviews](https://ai.stanford.edu/~amaas/data/sentiment/) with a Logistic Regression on a TF-IDF matrix.\n",
    "\n",
    "<a id='index'></a>\n",
    "## Index\n",
    "\n",
    "- [Data preprocessing](#preprocessing)\n",
    "- [Training a classifier](#classifier)\n",
    "- [Validation](#validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from validation import plot_confusion_matrix, visualise_predictions\n",
    "from preprocessing import preprocess, clean, tokenize, tokenize_n_stem, tokenize_n_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of test examples: 25000\n",
      "\n",
      "The first 5 reviews from the training set:\n",
      "\n",
      "                                              review  sentiment\n",
      "0  I was skimming over the list of films of Richa...          0\n",
      "1  I cringed all the way through this movie. Firs...          0\n",
      "2  This movie displayed more racial hatred of Jew...          0\n",
      "3  All I can say is, before watching the movie I ...          0\n",
      "4  This is easily the worst Presley vehicle ever,...          0\n",
      "\n",
      "The first 5 reviews from the test set:\n",
      "\n",
      "                                              review  sentiment\n",
      "0  Jerry Lewis was marginally funny when he didn'...          0\n",
      "1  I wish Depardieu had been able to finish his b...          0\n",
      "2  4 Oscar winners, Karl Malden, Sally Field, Shi...          0\n",
      "3  This movie was disturbing, not because of the ...          0\n",
      "4  This movie is so dull I spent half of it on IM...          0\n"
     ]
    }
   ],
   "source": [
    "IMDB_MOVIE_REVIEWS_ROOT = 'aclImdb'\n",
    "\n",
    "train_data, test_data = preprocess(IMDB_MOVIE_REVIEWS_ROOT)\n",
    "\n",
    "print(\"Number of training examples: %d\" % len(train_data))\n",
    "print(\"Number of test examples: %d\\n\" % len(test_data))\n",
    "\n",
    "print(\"The first 5 reviews from the training set:\\n\")\n",
    "print(train_data.head(5))\n",
    "\n",
    "print(\"\\nThe first 5 reviews from the test set:\\n\")\n",
    "print(test_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is terrible but it has some good effects.\n",
      "\n",
      "['movie', 'terrible', 'good', 'effects']\n",
      "\n",
      "['movi', 'terribl', 'good', 'effect']\n",
      "\n",
      "['movie', 'terrible', 'good', 'effect']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the shortest review\n",
    "raw_review = min(train_data['review'].values, key=len)\n",
    "\n",
    "print(\"%s\\n\" % raw_review)\n",
    "\n",
    "# Test tokenize function\n",
    "print(\"%r\\n\" % tokenize(clean(raw_review)))\n",
    "\n",
    "# Test tokenize_n_stem function\n",
    "print(\"%r\\n\" % tokenize_n_stem(clean(raw_review)))\n",
    "\n",
    "# Test tokenize_n_lemmatize function\n",
    "print(\"%r\\n\" % tokenize_n_lemmatize(clean(raw_review)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classifier'></a>\n",
    "## Training a classifier\n",
    "\n",
    "[back to index](#index)\n",
    "\n",
    "Grid Search is combined with cross-validation (k = 10) to identify the best combination parameters.\n",
    "\n",
    "- Documentation for GridSearchCV can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- Documentation for Pipeline can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- Documentation for TfidfVectorizer can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- Documentation for LogisticRegression can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 7\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifier = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'vectorizer__tokenizer' : [tokenize, tokenize_n_stem],\n",
    "    'vectorizer__max_df' : [0.8, 1.0],\n",
    "    'classifier__C' : [1.0, 10.0, 100.0],\n",
    "    'classifier__penalty' : ['l1', 'l2']\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    params,\n",
    "    scoring='accuracy',\n",
    "    cv=10,\n",
    "    n_jobs=3\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data['review'].values, train_data['sentiment'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation'></a>\n",
    "## Validation\n",
    "\n",
    "[back to index](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "y_test_hat = best_classifier.predict(test_data['review'].values)\n",
    "\n",
    "print(\"Best parameters set found on development set:\\n\\n\", best_params)\n",
    "\n",
    "print(\"\\nCV score: %.2f%%\" % (grid_search.best_score_ * 100))\n",
    "print(\"Test score: %.2f%%\" % (best_classifier.score(test_data['review'].values, test_data['sentiment'].values) * 100))\n",
    "\n",
    "print(\"\\nTest classification report:\\n\\n\")\n",
    "print(classification_report(test_data['sentiment'].values, y_test_hat))\n",
    "\n",
    "plot_confusion_matrix(test_data['sentiment'], y_test_hat, title='Test confusion matrix')\n",
    "#visualise_predictions(test_data['review'].values, test_data['sentiment'].values, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the best classifier\n",
    "save_to_dir = 'best_classifier'\n",
    "if not os.path.exists(save_to_dir):\n",
    "    os.mkdir(save_to_dir)\n",
    "joblib.dump(best_classifier, '%s/tfidf_logreg_pipeline.pkl' % save_to_dir, compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
